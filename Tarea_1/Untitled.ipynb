{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score,recall_score\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import N\n",
    "\n",
    "np.set_printoptions(formatter={\"float\":\"{:0.2f}\".format})\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\")\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generos  \n",
    "\n",
    "Un programa de salud gubernamental desea clasificar los registros de las personas en géneros Femenino (F) o Masculino (M) a partir de los atributos nombre, estatura y peso. Se cuentan con los siguientes registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombres</th>\n",
       "      <th>Estatura (m)</th>\n",
       "      <th>Peso (kg)</th>\n",
       "      <th>Genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Denis</td>\n",
       "      <td>1.72</td>\n",
       "      <td>75.3</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>1.82</td>\n",
       "      <td>81.6</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Alex</td>\n",
       "      <td>1.80</td>\n",
       "      <td>86.1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Alex</td>\n",
       "      <td>1.70</td>\n",
       "      <td>77.1</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Cris</td>\n",
       "      <td>1.73</td>\n",
       "      <td>78.2</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Juan</td>\n",
       "      <td>1.80</td>\n",
       "      <td>74.8</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Juan</td>\n",
       "      <td>1.80</td>\n",
       "      <td>74.3</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Denis</td>\n",
       "      <td>1.50</td>\n",
       "      <td>50.5</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Alex</td>\n",
       "      <td>1.52</td>\n",
       "      <td>45.3</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Cris</td>\n",
       "      <td>1.62</td>\n",
       "      <td>61.2</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Rene</td>\n",
       "      <td>1.67</td>\n",
       "      <td>68.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>1.65</td>\n",
       "      <td>58.9</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>Guadalupe</td>\n",
       "      <td>1.75</td>\n",
       "      <td>68.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Nombres  Estatura (m)  Peso (kg) Genero\n",
       "0       Denis          1.72       75.3      M\n",
       "1   Guadalupe          1.82       81.6      M\n",
       "2        Alex          1.80       86.1      M\n",
       "3        Alex          1.70       77.1      M\n",
       "4        Cris          1.73       78.2      M\n",
       "5        Juan          1.80       74.8      M\n",
       "6        Juan          1.80       74.3      M\n",
       "7       Denis          1.50       50.5      F\n",
       "8        Alex          1.52       45.3      F\n",
       "9        Cris          1.62       61.2      F\n",
       "10       Rene          1.67       68.0      F\n",
       "11  Guadalupe          1.65       58.9      F\n",
       "12  Guadalupe          1.75       68.0      F"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data ={\n",
    "   \"Nombres\":[\"Denis\",\"Guadalupe\",\"Alex\",\"Alex\", \"Cris\",\n",
    "               \"Juan\",\"Juan\",\"Denis\",\"Alex\",\"Cris\",\"Rene\",\"Guadalupe\",\"Guadalupe\"],\n",
    "   \"Estatura (m)\":[1.72,1.82,1.8,1.7,1.73,1.8,1.8,1.5,1.52,1.62,1.67,1.65,1.75],\n",
    "   \"Peso (kg)\":[75.3,81.6,86.1,77.1,78.2,74.8,74.3,50.5,45.3,61.2,68.0,58.9,68.0],\n",
    "   \"Genero\":[\"M\",\"M\",\"M\",\"M\",\"M\",\"M\",\"M\",\"F\",\"F\",\"F\",\"F\",\"F\",\"F\"],\n",
    "   }\n",
    "\n",
    "df = pd.DataFrame(data, columns = [\"Nombres\",\"Estatura (m)\",\"Peso (kg)\",\"Genero\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena un clasificador bayesiano ingenuo usando estimación por máxima verosimilitud y otro usando estimación por máximo a posteriori. Reporta los parámetros que obtuviste en embos casos y usa los clasificadores entrenados para predecir la clase de los siguientes vectores \n",
    "\n",
    "$$x_{1} = (\\text{Rene},1.68,65)$$\n",
    "$$x_{2} = (\\text{Guadalupe},1.75,80)$$\n",
    "$$x_{3} = (\\text{Denis},1.80,79)$$\n",
    "$$x_{4} = (\\text{Alex},1.90,85)$$\n",
    "$$x_{5} = (\\text{Cris},1.65,70)$$\n",
    "\n",
    "\n",
    "Describe de forma detallada el procedimiento que seguiste tante en el entrenamiento como en la predicción y discute los resultados obtenidos. Para el entrenamiento del clasificador por máximo a posteriori considera los siguientes valores para las distribuciones correspondientes \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 2\n",
    "muoEM = 1.7;  muoEF = 1.5;  sigmaoEM_2 = 0.3;  sigmaoEF_2 = 0.1\n",
    "muoPM = 85.5; muoPF = 70.3; sigmaoPM_2 = 17.0; sigmaoPF_2 = 85.0\n",
    "\n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se contabiliza el número de elementos de cada clase y el número total de datos. Vamos a implementar un clasificador bayesano ingenuo utilizando estimadores de máxima verosimilitud y máximo a posteriori . A continuación el cálculo de los estimadores de EMV dadas por las siguientes expresiones\n",
    "\n",
    "\n",
    "$$\\hat{\\mu}_{EMV}=\\frac{1}{n}\\sum_{j=1}^{n}x^{(j)} \\qquad \\hat{\\sigma}^{2}_{EMV} = \\frac{1}{n}\\sum_{j=1}^{n}(x^{(j)}-\\hat{\\mu}_{EMV})^{2} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Estatura Masculino   = 1.767\n",
      " Estatura Femenino    = 1.618\n",
      " Peso Masculino       = 78.200\n",
      " Peso Femenino        = 58.650\n"
     ]
    }
   ],
   "source": [
    "NM = float(sum(data[:,-1:] == \"M\")) # Number of class H data\n",
    "NF = float(sum(data[:,-1:] == \"F\")) # Number of class F data\n",
    "NT  = np.shape(data)[0]             # Total number of data\n",
    "\n",
    "mu_Est = np.mean(data[:,1:2]) ; std_Est = np.std(data[:,1:2]) \n",
    "mu_Pes = np.mean(data[:,2:3]) ; std_Pes = np.std(data[:,2:3])\n",
    "\n",
    "Mas = data[data[:,-1]==\"M\"][:,:-1]\n",
    "Fem = data[data[:,-1]==\"F\"][:,:-1]\n",
    "NamM = data[data[:,-1]==\"M\"][:,:1]\n",
    "NamF = data[data[:,-1]==\"F\"][:,:1]\n",
    "\n",
    "\n",
    "# Normal distribution\n",
    "mu_EM = np.mean(Mas[::,-2]); std_EM = np.std(Mas[::,-2])\n",
    "mu_EF = np.mean(Fem[::,-2]); std_EF = np.std(Fem[::,-2])\n",
    "mu_PM = np.mean(Mas[::,-1]); std_PM = np.std(Mas[::,-1])\n",
    "mu_PF = np.mean(Fem[::,-1]); std_PF = np.std(Fem[::,-1])\n",
    "\n",
    "# Categorical Distribution\n",
    "q_M = np.asarray(np.unique(NamM,return_counts=True))\n",
    "q_F = np.asarray(np.unique(NamF,return_counts=True))\n",
    "\n",
    "qM_prov = {q_M[0][i]:q_M[1][i] for i in range(len(q_M[0]))}\n",
    "qF_prov = {q_F[0][i]:q_F[1][i] for i in range(len(q_F[0]))}\n",
    "\n",
    "mu = np.array([mu_EM,mu_PM,mu_EF,mu_PF])\n",
    "std = np.array([std_EM,std_PM,std_EF,std_PF]) \n",
    "\n",
    "print(\" Estatura Masculino   = {0:.3f}\".format(mu_EM))\n",
    "print(\" Estatura Femenino    = {0:.3f}\".format(mu_EF))\n",
    "print(\" Peso Masculino       = {0:.3f}\".format(mu_PM))\n",
    "print(\" Peso Femenino        = {0:.3f}\".format(mu_PF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema se tiene que considerar una función de distribución de probabilidad para cada atributo , en el caso del nombre se uliza una distribución categórica y para la estatura y el peso una distribución normal dadas por las siguientes expresiones\n",
    "\n",
    "$$\\mathcal{N}(\\vec{x}|\\mu,\\sigma^{2})=\\frac{1}{(2\\pi\\sigma)^{1/2}}e^{-\\frac{1}{2\\sigma^{2}}(x-\\mu)^{2}} \\qquad f(x;\\vec{q})=\\prod_{\\kappa=1}^{K}q_{\\kappa}^{[x=\\kappa]}$$\n",
    "\n",
    "donde los estimadores de la distribución categórica están dado por \n",
    "\n",
    "$$\\hat{q}_{\\kappa} = \\frac{c_{\\kappa}}{n},\\qquad c_{\\kappa}=\\sum_{i=1}^{n}[x=\\kappa]$$\n",
    "\n",
    "\n",
    "Luego se plantea el uso del clasificador como sigue \n",
    "\n",
    "$$C= \\underset{C\\in\\{Nomb,Est,peso\\}}{\\mathrm{ArgMax}} \\left[ P(C)\\prod_{n=1}^{N}\\mathcal{N}(x_{n}|\\mu,\\sigma_{2})q_{n}^{[x=n]}\\right], \\qquad c_{n} = \\sum_{i=1}^{n}[x=n] $$\n",
    "\n",
    "En donde $P(C)$ sigue una distribución binomial dado que se debe elegir entre \"Masculino\" y \"Femenino\".\n",
    "\n",
    "Se costruye la función que hace la comparacion entre los clasificadores y se define una matriz que contiene los datos que se deben predecir \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MVE(x):\n",
    "   InCMdata = x[0] in qM_prov; InCFdata = x[0] in qF_prov\n",
    "   CM = 0; CF = 0\n",
    "   \n",
    "   if InCMdata == True:\n",
    "      CM = (NM/NT)*np.prod(N(x[1:],mu[:2],std[:2]))*qM_prov[str(x[0])]/NM\n",
    "   if InCFdata == True:\n",
    "      CF = (NF/NT)*np.prod(N(x[1:],mu[2:4],std[2:4]))*qF_prov[str(x[0])]/NF\n",
    "   clases = {CM:\"Masculino\",CF:\"Femenino\"}\n",
    "   return x,clases[max(CM,CF)],CM,CF\n",
    "\n",
    "#Muestra para predecir \n",
    "X_p =  [[\"Rene\",1.68,65.],\n",
    "             [\"Guadalupe\",1.75,80.],\n",
    "             [\"Denis\",1.80,79.],\n",
    "             [\"Alex\",1.90,85.],\n",
    "             [\"Cris\",1.65,70]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se presentan las predicciones que proporciona el modelo  usando EMV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Rene', 1.68, 65.0], 'Femenino', 0, 0.024617189167210275)\n",
      "(['Guadalupe', 1.75, 80.0], 'Femenino', 0.03453817661333737, 2.2776213815668176)\n",
      "(['Denis', 1.8, 79.0], 'Femenino', 0.03863089376964986, 2.4307667134297692)\n",
      "(['Alex', 1.9, 85.0], 'Femenino', 19.818789779153725, 392.27808779856326)\n",
      "(['Cris', 1.65, 70], 'Masculino', 7.295540261399398, 0.03803909213190314)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_p)):\n",
    "   print(MVE(X_p[i]))\n",
    "\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que sigue se debe calcular las constantes para el MAP, que vienen dadas por \n",
    "\n",
    "$$\\hat{\\mu} = \\frac{\\sigma_{o}^{2}\\left(\\sum_{i=1}^{n}x^{(i)}\\right)-\\sigma^{2}\\mu_{o}}{\\sigma^{2}_{o}n+\\sigma^{2}}\\qquad \\text{Distribución normal}$$\n",
    "\n",
    "$$\\hat{q}_{k} = \\frac{c_{k}+\\alpha_{k}-1}{n+\\sum_{k=1}^{K}\\alpha_{k} - K} \\qquad \\text{Distribución categórica}$$\n",
    "\n",
    "Ahora se calculan estos parámetros\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatura Masculino   = 1.767078321148749\n",
      "Peso Masculino       = 69.05296940116787\n",
      "Estatura Femenino    = 1.6168825823917028\n",
      "Peso Femenino        = 51.48287713140879\n"
     ]
    }
   ],
   "source": [
    "mu_EM2 = (sigmaoEM_2*sum(Mas[::,-2])+(std_EM**2)*muoEM)/(sigmaoEM_2*NM + std_EM**2)\n",
    "mu_EF2 = (sigmaoEF_2*sum(Fem[::,-2])+(std_EF**2)*muoEF)/(sigmaoEF_2*NF + std_EF**2)\n",
    "mu_PM2 = (sigmaoPM_2*sum(Mas[::,-1])+(std_EM**2)*muoPM)/(sigmaoPM_2*NM + std_PM**2)\n",
    "mu_PF2 = (sigmaoPF_2*sum(Fem[::,-1])+(std_EF**2)*muoPF)/(sigmaoPF_2*NF + std_PF**2)\n",
    "\n",
    "mu2 = np.array([mu_EM2,mu_PM2,mu_EF2,mu_PF2])\n",
    "print(\"Estatura Masculino   = {}\".format(mu2[0]))\n",
    "print(\"Peso Masculino       = {}\".format(mu2[1]))\n",
    "print(\"Estatura Femenino    = {}\".format(mu2[2]))\n",
    "print(\"Peso Femenino        = {}\".format(mu2[3]))\n",
    "\n",
    "qM_prov = {q_M[0][i]:q_M[1][i] for i in range(len(q_M[0]))}\n",
    "qF_prov = {q_F[0][i]:q_F[1][i] for i in range(len(q_F[0]))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros de la categórica se implementan dentro de la funcion de estimación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAP(x):\n",
    "   InCMdata = x[0] in qM_prov; InCFdata = x[0] in qF_prov\n",
    "   CM = 0; CF = 0\n",
    "   \n",
    "   if InCMdata == True:\n",
    "      CM = (NM/NT)*np.prod(N(x[1:],mu2[:2],std[:2]))*(qM_prov[str(x[0])]+alpha-1)/(NM+alpha*NM-NM)\n",
    "   if InCFdata == True:\n",
    "      CF = (NF/NT)*np.prod(N(x[1:],mu2[2:4],std[2:4]))*(qF_prov[str(x[0])]+alpha-1)/(NF+alpha*NF-NF)\n",
    "   clases = {CM:\"Masculino\",CF:\"Femenino\"}\n",
    "   return x,clases[max(CM,CF)],CM,CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace la predicción de los datos propuestos por el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Rene', 1.68, 65.0], 'Femenino', 0, 0.06791228839361729)\n",
      "(['Guadalupe', 1.75, 80.0], 'Femenino', 1.3931693913720178, 21.71152757385047)\n",
      "(['Denis', 1.8, 79.0], 'Femenino', 0.8736988274721701, 28.202435888090267)\n",
      "(['Alex', 1.9, 85.0], 'Masculino', 10959.21442120047, 8503.619880250359)\n",
      "(['Cris', 1.65, 70], 'Masculino', 0.8864686998045899, 0.17281196558926418)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X_p)):\n",
    "   print(MAP(X_p[i]))\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Spam \n",
    "\n",
    "Dado el conjunto de datos \"spam.csv\" y realiza los siguientes ejercicios. El archivo *spam.csv* contiene 2001 valores por cada renglon de los cuales los primeros 2000 representan el histograma de palabras de un correo y el último corresponde a la clase , esto es, 1 si es spam y 0 si no lo es \n",
    "\n",
    "Esta es la base de datos, los extraemos y ponemos en forma adecuada para trabajar con numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\")\n",
    "data = df.to_numpy()\n",
    "\n",
    "x = []\n",
    "for i in range(len(data)):\n",
    "    x.append(np.array([float(i) for i in data[i][0].split()]))\n",
    "x = np.array(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reporta el porcentaje de correos que están etiquetados como spam y como no spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcentaje de corres Spam            = 0.290\n",
      "Porcentaje de corres que no son Spam = 0.710\n"
     ]
    }
   ],
   "source": [
    "Num_Spam = sum(x[:,-1] == True)\n",
    "Num_NSpam = sum(x[:,-1] == False)\n",
    "\n",
    "print(\"Porcentaje de corres Spam            = {0:.3f}\".format(Num_Spam/len(data)))\n",
    "print(\"Porcentaje de corres que no son Spam = {0:.3f}\".format(Num_NSpam/len(data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Divide aleatoriamente el conjunto de datos en el 70% para entrenamiento y el 30% restante para validación usando 0 como semilla para tu generador de n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganizacion de las listas\n",
    "x = np.random.permutation(x)\n",
    "#eleccion de los datos de entrenamiento \n",
    "x_train = x[0:int(len(x)*0.7)]\n",
    "x_val = x[int(len(x)*0.7)-1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Entrena 2 clasificadores bayesianos ingenuos con distintas distribuciones \n",
    "\n",
    "vamos a ver que tipos de clases tenemos , para poder calcular los parametros de cada clase separamos en dos grupos, los que son spam y los que no para calcular los respectivos $q_{k}$ de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "NS = sum(x_train[:,-1] == True)\n",
    "NNS = sum(x_train[:,-1] == False)\n",
    "Nt = len(x_train) \n",
    "\n",
    "spam_train  = x_train[x_train[:,-1]==1][:,0:-1]\n",
    "Nspam_train = x_train[x_train[:,-1]==0][:,0:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asumimos que en nuestro problema las clases se distribuyen como una distribucion Bernoulli dado por \n",
    "\n",
    "$$P(C) = q^{C}(1-q)^{1-C} \\qquad \\hat{q}_{C}=\\frac{N_{c}}{N}$$\n",
    "\n",
    "esto para cada clase será"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimador clase spam    = 0.294\n",
      "Estimador clase no spam = 0.706\n"
     ]
    }
   ],
   "source": [
    "qs = NS/Nt\n",
    "qns = NNS/Nt\n",
    "\n",
    "print(\"Estimador clase spam    = {0:.3f}\".format(qs))\n",
    "print(\"Estimador clase no spam = {0:.3f}\".format(qns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se estiman las verosimilitudes asumiendo que los datos se distribuyen como una multinomial dada por la siguiente expresión \n",
    "\n",
    "$$P(x|C) = \\frac{n!}{\\prod_{t=1}^{|v|}}\\prod_{t=1}^{|v|}q(w_{t}|C)^{x_{t}}$$\n",
    "\n",
    "Sin embargo, podemos ignorar el término de normalización para calcular la siguiente expresión\n",
    "\n",
    "$$P(x|C) \\propto \\prod_{t=1}^{|v|}q(w_{t}|C)^{x_{t}} $$\n",
    "\n",
    "Para estimar cada parametro de cada clase tenemos que tener en cuenta la frecuencia de la palabra en cada clase dadas por $n_{c}(w_{t})$\n",
    "\n",
    "$$\\hat{q}(w_{t}|C) = \\frac{n_{C}(w_{t})}{\\sum_{s=1}^{|V|}n_{C}(w_{t})}$$\n",
    "\n",
    "Se cuenta el número de ocurrencias de las palabras en las clases $n_{C}(w_{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = spam_train.sum(axis=0)/spam_train.sum()\n",
    "pNst = Nspam_train.sum(axis=0)/Nspam_train.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se construye el clasificador asumiendo que le entra un renglon que representa un correo, que es el histograma de palabras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Clasificador(x):\n",
    "    x_t = x[:-1]\n",
    "    Cs = qs*np.power(pst,x).prod()\n",
    "    CNs = qns*np.power(pNst,x).prod()\n",
    "    clases={Cs:1.0,CNs:0.0}\n",
    "    return clases[max(Cs,CNs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se verifica el grupo de validación corroborando cuantos casos se acierta en la predicción dada la etiqueta de los datos de validacion \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de validación    = 0.925\n",
      "Conjunto de entrenamiento = 0.936\n"
     ]
    }
   ],
   "source": [
    "xprueba = []\n",
    "xprueba2 = []\n",
    "for i in range(len(x_val)):\n",
    "    xprueba.append(Clasificador(x_val[i][:-1]))\n",
    "    xprueba2.append(Clasificador(x_train[i][:-1]))\n",
    "    \n",
    "m = sum([x_train[i][-1] == xprueba2[i] for i in range(len(xprueba2))])/len(xprueba2)\n",
    "\n",
    "print(\"Conjunto de validación    = {0:.3f}\".format(sum(xprueba==x_val[::,-1])/len(x_val)))\n",
    "print(\"Conjunto de entrenamiento = {0:.3f}\".format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el otro modelo se utilizan las librerias sklearn que tienen dentro de si varias distribuciones de probabilidad en las cuales podemos probrar el rendimiento, empezemos a probar con varias probabilidades y al final se comparan los resultados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construcción de modelos\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB, BernoulliNB, GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score,recall_score\n",
    "\n",
    "clf1 = MultinomialNB(alpha= 0.1,fit_prior=True,class_prior=None)\n",
    "clf2 = ComplementNB(alpha= 0.1,fit_prior=True)\n",
    "clf3 = BernoulliNB(alpha=0.1,fit_prior=False,binarize=1)\n",
    "\n",
    "X_train = x_train[:,0:-1]\n",
    "y_train = x_train[::,1]\n",
    "\n",
    "clf1.fit(X_train,y_train)\n",
    "clf2.fit(X_train,y_train)\n",
    "clf3.fit(X_train,y_train)\n",
    "\n",
    "print(\"Construcción de modelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial \n",
    "\n",
    "Implementa el algoritmo de Naive Bayes para datos distribuidos de forma multinomial, es uno de las dos variantes clásicas del algoritmo de Naive Bayes usado en clasificación de textos, en donde los datos están representado como un \"vector de palabras\". La distribución está parametrizada por los vectores $\\vec{\\theta}_{y} = (\\theta_{y1},\\cdots,\\theta_{yn})$ para cada clase $y$, donde $n$ es el numero de características (en particular en este caso de texto de clasificación es el tamaño de vocabulario) y $\\theta_{yi}$ es la probabilidad $P(x_{i}|y)$ de la característica $i$ que aparece en la muestra de datos perteneciente a la clase $y$. \n",
    "\n",
    "Los parámetros $\\theta_{y}$ son estimados de una version \"suavizada\" de máxima verosimilitud, es decir, como frecuencia relativa , conteo\n",
    "\n",
    "$$\\hat{\\theta}_{yi} = \\frac{N_{yi}+\\alpha}{N_{y}+\\alpha n}$$\n",
    "\n",
    "Donde $N{yi} = \\sum_{x\\in T}x_{i}$ es el número de veces que la característica etiquetada con $i$ aparece en la muestra de la clase $y$ en el conjunto de entrenamiento $T$ y $N_{y} = \\sum_{i=1}^{n}N_{yi}$ es el contéo de todas las características de la clase $y$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complemento\n",
    "\n",
    "Implementa el algoritmo llamado \"Complement Naive Bayes\" (CNB). Es una adaptación del me'todo estándar multinomial, descrito anteriormente. Se utiliza particularmente para datos desbalanceados. Este modelo utiliza estadísticas de comlemento de cada clase para calcular los pesos del modelo. Además CNB supera al Multinomial en tareas como clasificacion de texto.\n",
    "\n",
    "El procedimiento para calcular los pesos es el siguiente\n",
    "\n",
    "$$\\hat{\\theta}_{ci} = \\frac{\\alpha_{i}+\\sum_{j:y_{j}\\neq c}d_{ij}}{\\alpha + \\sum_{j:y_{j}\\neq c}d_{kj}} \\qquad \\omega_{ci} = \\log\\hat{\\theta}_{ci}=\\frac{\\omega_{ci}}{\\sum_{j}|\\omega_{cj}|}$$\n",
    "\n",
    "Donde las sumas corren sobre todos los documentos $j$ no en la clase c, $d_{ij}$ es el recuento de los valores $i$ en el documento $j$ con $\\alpha_{i}$el hiperparámetro de \"suavidad\" tal como en la distribución Multinomial. La regla de clasificaciónesta dada por \n",
    "\n",
    "$$C= \\underset{C\\in\\{Spam,NoSpam\\}}{\\mathrm{ArgMin}} \\left[ P(C)\\prod_{n=1}^{N}\\mathcal{N}(x_{n}|\\mu,\\sigma_{2})\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli \n",
    "\n",
    "Implementa un clasificador Naive Bayes para datos que se distribuyen de acuerdo a la distribucion multivariada de Bernoulli, puede considerar multimples caractterísticas pero cada una de ellas se asume como un problema dicotomico. Entonces, este método requiere muestras que representen características binarias evaluadas en vectores, dado el caso que la entrada no sea binaria la instancia *binarize* pone la referencia para convertir los datos a binario.\n",
    "\n",
    "La regla de decisión está dada por \n",
    "\n",
    "$$P(x_{i}|y) = P(i|y)x_{i}+(1-P(i|y))(1-x_{i})$$\n",
    "\n",
    "Difiere del algoritmo multinomial porque penaliza la no ocurrencua de la característica $i$, que es el indicador de la clase $y$, donde el equivalente peso esn la distribución multinomial es ignorado cuando no se tiene la característica.\n",
    "\n",
    "Referente a la clasificación de texto, se pueden usar vectores de aparicion de palabras (en lugar de vectores de recuento de palabras) para entrenar y usar este clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se hace la validación para cada modelo construido "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisión Multinomial = 0.73\n",
      "precisión Complemento = 0.72\n",
      "precisión Bernoulli   = 0.74\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred1 = []\n",
    "pred2 = []\n",
    "pred3 = []\n",
    "\n",
    "for i in range(len(x_val)):\n",
    "    pred1.append(clf1.predict(np.reshape(x_val[i][:-1],(1,2000))))\n",
    "    pred2.append(clf2.predict(np.reshape(x_val[i][:-1],(1,2000))))\n",
    "    pred3.append(clf3.predict(np.reshape(x_val[i][:-1],(1,2000))))\n",
    "\n",
    "\n",
    "print(\"precisión Multinomial = {0:.2f}\".format(accuracy_score(x_val[::,-1], pred1)))\n",
    "print(\"precisión Complemento = {0:.2f}\".format(accuracy_score(x_val[::,-1], pred2)))\n",
    "print(\"precisión Bernoulli   = {0:.2f}\".format(accuracy_score(x_val[::,-1], pred3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Discute el desempeño de los clasificadores \n",
    "\n",
    "En cuanto al rendimiento de los clasificadores en este caso se puede observar mayor renidmiento del algoritmo que se hizo, esto puede darse por multiples factores, sin embargo podemos pensar en algunos que pueden ser fundamentales. El primero de ellos es la elección adecuada de los hiperparámetros que permitan maximizar el rendimiento de los clasificadores y la naturaleza y problemas que puedan abordar cada uno de ellos. \n",
    "\n",
    "Otro problema que se considera crucial es el hecho que no se sabe a profundidad el funcionamiento del algoritmo, por tal razón no se puede manejar con toda potencialidad el método a diferencia de los programados solamente utilizando NumPy y Pandas, dado que se conoce como se estructuro el algoritmo y se pueden hacer modificaciones para incluir mayor desempeño en el clasificador\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Cáncer de seno \n",
    "\n",
    "Divide aleatoriamente el conjunto de datos de cancer de serno de Wisconsin en un subconjunto de entrenamiento con el 70% de los datos y un subconjunto de validación con el 30% restante usando 0 como semilla para tu generador de numeros aleatorios. Este conjunto de datos contiene 699 registros de tumores de seno, de los cuales 458 son beningnos y 241 son malignos. Cada registri consta de lo siguientes atributos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Grosor del tumor</th>\n",
       "      <th>Uniformidad tamaño</th>\n",
       "      <th>forma celula</th>\n",
       "      <th>Adhesion marginal</th>\n",
       "      <th>Tamaño celula epitelial</th>\n",
       "      <th>Nucleos desnudos</th>\n",
       "      <th>Cromatina blanda</th>\n",
       "      <th>Núcleolos normales</th>\n",
       "      <th>Mitosis de celulas</th>\n",
       "      <th>Clase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000025</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1002945</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1015425</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1016277</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1017023</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>694</td>\n",
       "      <td>776715</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>695</td>\n",
       "      <td>841769</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>696</td>\n",
       "      <td>888820</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>697</td>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>698</td>\n",
       "      <td>897471</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID   Grosor del tumor  Uniformidad tamaño  forma celula  \\\n",
       "0    1000025                 5                   1             1   \n",
       "1    1002945                 5                   4             4   \n",
       "2    1015425                 3                   1             1   \n",
       "3    1016277                 6                   8             8   \n",
       "4    1017023                 4                   1             1   \n",
       "..       ...               ...                 ...           ...   \n",
       "694   776715                 3                   1             1   \n",
       "695   841769                 2                   1             1   \n",
       "696   888820                 5                  10            10   \n",
       "697   897471                 4                   8             6   \n",
       "698   897471                 4                   8             8   \n",
       "\n",
       "     Adhesion marginal  Tamaño celula epitelial Nucleos desnudos  \\\n",
       "0                    1                        2                1   \n",
       "1                    5                        7               10   \n",
       "2                    1                        2                2   \n",
       "3                    1                        3                4   \n",
       "4                    3                        2                1   \n",
       "..                 ...                      ...              ...   \n",
       "694                  1                        3                2   \n",
       "695                  1                        2                1   \n",
       "696                  3                        7                3   \n",
       "697                  4                        3                4   \n",
       "698                  5                        4                5   \n",
       "\n",
       "     Cromatina blanda  Núcleolos normales  Mitosis de celulas  Clase  \n",
       "0                   3                   1                   1      2  \n",
       "1                   3                   2                   1      2  \n",
       "2                   3                   1                   1      2  \n",
       "3                   3                   7                   1      2  \n",
       "4                   3                   1                   1      2  \n",
       "..                ...                 ...                 ...    ...  \n",
       "694                 1                   1                   1      2  \n",
       "695                 1                   1                   1      2  \n",
       "696                 8                  10                   2      4  \n",
       "697                10                   6                   1      4  \n",
       "698                10                   4                   1      4  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Names = [\"ID \",\"Grosor del tumor\",\"Uniformidad tamaño\",\n",
    "            \"forma celula\",\"Adhesion marginal\",\"Tamaño celula epitelial\",\n",
    "            \"Nucleos desnudos\",\"Cromatina blanda\",\"Núcleolos normales\",\n",
    "           \"Mitosis de celulas\",\"Clase\"]\n",
    "df1 = pd.read_csv(\"breast-cancer-wisconsin.data\",names =Names)\n",
    "df1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrena un clasificador Bayesiano ingenuo de tumores de seno y evalúalo tanto con el subconjunto de entrenamiento como con el subjconjunto de validación y discute su desempeño. Existen 16 registros en el conjunto de datos con un atributo no especificado.  Investiga estrategias para rellenar los datos faltantes, utiliza las que consideres más adecuadas para este problema y discute el impacto en el desempeño del clasificador.\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se trabaja con arreglos de numpy para alguno calculos numéricos , luego se cambia el orden de los datos. En principio se entrena un clasificador sin los datos faltantes para tenerlo como referencia y ver si queda bien hecho el clasificador sto se hace identificando los datos inexistentes, utilizando la función *where* que retorna la columna y el indice en donde  existe un dato identificado como \"?\", que se debe rellenar antes de poder calcular los estimadores del clasificador bayesiano ingenuo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.permutation(data)\n",
    "index = np.where(data == \"?\")\n",
    "data_ref = np.delete(data,index,axis=0)\n",
    "\n",
    "x_train = data_ref[0:int(len(data_ref)*0.7)]  #70% entrenamiento\n",
    "x_val = data_ref[int(len(data_ref)*0.7)-1:-1] #30% validacion\n",
    "x_val = x_val.astype(np.float)\n",
    "\n",
    "# correcion de tipo de datos en la 6 columna para trabajar con float\n",
    "x_val[:,6] = x_val[:,6].astype(np.float) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se hace ahora es clasificar en dos grupos de datos, los pertenecientes al grupo Beningno que se identifican con el valor \"2\" y otro del grupo Maligno identificado con el \"4\". Esto con el fin de calcular los estimadores correspondientes a cada clase de cada atributo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de Tumores Beningnos = 161\n",
      "Numero de Tumores Malignos  = 316\n",
      "Numero datos totales entrenamiento = 477\n"
     ]
    }
   ],
   "source": [
    "Benigno = x_train[x_train[:,-1]==4]\n",
    "Benigno[:,6] = Benigno[:,6].astype(np.float) \n",
    "\n",
    "Maligno = x_train[x_train[:,-1]==2]\n",
    "Maligno[:,6] = Maligno[:,6].astype(np.float) \n",
    "\n",
    "NB_ref = len(Benigno)\n",
    "NM_ref = len(Maligno)\n",
    "NT = NB_ref + NM_ref\n",
    "\n",
    "\n",
    "print(\"Numero de Tumores Beningnos = {}\".format(NB_ref))\n",
    "print(\"Numero de Tumores Malignos  = {}\".format(NM_ref))\n",
    "print(\"Numero datos totales entrenamiento = {}\".format(NT))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso vamos a muestrear nuestros valores pertenecientes a cada atributo asumiendo que siguen una distribución normal dada por \n",
    "\n",
    "$$\\mathcal{N}(\\vec{x}|\\mu,\\sigma^{2})=\\frac{1}{(2\\pi\\sigma)^{1/2}}e^{-\\frac{1}{2\\sigma^{2}}(x-\\mu)^{2}}$$\n",
    "\n",
    "Suponemos que el conjunto de observaciones de los atributos de las variables se distribuyen de manera uniforme y son independientes entre si. Vemos que la probabilidad conjunta de dos eventos independientes está dada por el producto de las probabilidades marginales para cada evento por separa, esto se representa de la siguiente \n",
    "\n",
    "$$P(\\vec{x}|\\mu,\\sigma^{2}) = \\prod_{n=1}^{N}\\mathcal{N}(x_{n}|\\mu,\\sigma_{2})$$\n",
    "\n",
    "luego los clasificadores se calculan de la siguiente manera \n",
    "\n",
    "$$C= \\underset{C\\in\\{Spam,NoSpam\\}}{\\mathrm{ArgMax}} \\left[ P(C)\\prod_{n=1}^{N}\\mathcal{N}(x_{n}|\\mu,\\sigma_{2})\\right] $$\n",
    "\n",
    "Utilizando el estimador de máxima verosimilitud los parámetros de la distribución son el promedio y la varianza, dadas por \n",
    "\n",
    "$$\\hat{\\mu}_{EMV} = \\frac{1}{n}\\sum_{i=1}^{n}x^{(i)}\\qquad \\hat{\\sigma}^{2}_{EMV} = \\frac{1}{n}(x^{(i)}-\\hat{\\mu}_{EMV})^{2}$$\n",
    "\n",
    "Entonces podemos calcular estos parámetros de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.62, 0.88, 0.89, 0.77, 0.89, 1.13, 0.98, 0.94, 0.59])"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculo de los parámetros de cada clase\n",
    "\n",
    "muM = [np.mean(Maligno[:,1:-1][:,i]) for i in range(np.shape(Maligno[:,1:-1])[1])]\n",
    "muM = np.array(muM)\n",
    "stdM = [np.std(Maligno[:,1:-1][:,i]) for i in range(np.shape(Maligno[:,1:-1])[1])]\n",
    "stdM = np.array(stdM)\n",
    "\n",
    "muB = [np.mean(Benigno[:,1:-1][:,i]) for i in range(np.shape(Benigno[:,1:-1])[1])]\n",
    "muB = np.array(muB)\n",
    "stdB = [np.std(Benigno[:,1:-1][:,i]) for i in range(np.shape(Benigno[:,1:-1])[1])]\n",
    "stdB = np.array(stdB)\n",
    "\n",
    "stdM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos son los parámetros obtenidos para cada atributo de cada grupo de datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promedio Beningno =[7.35 6.65 6.71 5.65 5.40 7.86 6.07 6.01 2.62]\n",
      "promedio Maligno  =[2.91 1.33 1.36 1.31 2.10 1.34 2.09 1.27 1.08]\n",
      "desviacion Beningno =[2.30 2.78 2.60 3.12 2.45 2.96 2.26 3.26 2.62]\n",
      "desviacion Maligno  =[1.62 0.88 0.89 0.77 0.89 1.13 0.98 0.94 0.59]\n"
     ]
    }
   ],
   "source": [
    "# promedio\n",
    "print(\"promedio Beningno ={}\".format(muB))\n",
    "print(\"promedio Maligno  ={}\".format(muM))\n",
    "\n",
    "# desviacion estandar\n",
    "\n",
    "print(\"desviacion Beningno ={}\".format(stdB))\n",
    "print(\"desviacion Maligno  ={}\".format(stdM))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se construye una funcion que calcule las constante para cada clase y nos entregue la predicción, por tanto se tiene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MVE(x):\n",
    "    id_muestra = x[0]\n",
    "    x = x[1:-1]\n",
    "    CB = (NB_ref/NT)*np.prod(N(x,muB,stdB))\n",
    "    CM = (NM_ref/NT)*np.prod(N(x,muM,stdM))\n",
    "    clases={CM:4.0,CB:2.0}\n",
    "    return id_muestra, clases[max(CB,CM)] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a ver una predicción utilizando el conjunto de datos de validación, contando los aciertos de cada uno de los datos que proporciona el conjunto de validación y contrastando con el obtenido por el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rend(x_val):\n",
    "    val = np.array([MVE(x_val[i]) for i in range(len(x_val))])\n",
    "    y = val[:,-1]  == x_val[:,-1]\n",
    "    return sum(y)/len(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Rendimiento del clasificador = {}\".format(rend(x_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este fue el modelo entrenado para el conjunto de datos que no incluye los datos que contenían \"?\", ahora se buscan propuestas para rellenar los datos faltanes tratando de obtener el mayor rendimiento segun la funcion construida anteriormente. \n",
    "\n",
    "Para esto debemos hacer que haga muchas pruebas en los 16 datos y asi elegir el valor que mas rendimiento de en el clasificador. Se construyen las funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9365853658536586\n",
      "[4 2 3 1 6 6 0 8 1 6 3 9 4 3 2 4]\n"
     ]
    }
   ],
   "source": [
    "def entrenamiento(data,comb):\n",
    "    data = np.random.permutation(data)\n",
    "    index = np.where(data == \"?\")\n",
    "    data[index] = comb\n",
    "\n",
    "\n",
    "    x_train = data[0:int(len(data)*0.7)]  #70% entrenamiento\n",
    "    x_val = data[int(len(data)*0.7)-1:-1] #30% validacion\n",
    "    x_val[:,6] = x_val[:,6].astype(np.float) \n",
    "\n",
    "\n",
    "    Benigno = x_train[x_train[:,-1]==4]\n",
    "    Benigno[:,6] = Benigno[:,6].astype(np.float) \n",
    "\n",
    "    Maligno = x_train[x_train[:,-1]==2]\n",
    "    Maligno[:,6] = Maligno[:,6].astype(np.float) \n",
    "\n",
    "    NB_ref = len(Benigno)\n",
    "    NM_ref = len(Maligno)\n",
    "    NT = NB_ref + NM_ref\n",
    "\n",
    "    muM = [np.mean(Maligno[:,1:-1][:,i]) for i in range(np.shape(Maligno[:,1:-1])[1])]\n",
    "    muM = np.array(muM)\n",
    "    stdM = [np.std(Maligno[:,1:-1][:,i]) for i in range(np.shape(Maligno[:,1:-1])[1])]\n",
    "    stdM = np.array(stdM)\n",
    "\n",
    "    muB = [np.mean(Benigno[:,1:-1][:,i]) for i in range(np.shape(Benigno[:,1:-1])[1])]\n",
    "    muB = np.array(muB)\n",
    "    stdB = [np.std(Benigno[:,1:-1][:,i]) for i in range(np.shape(Benigno[:,1:-1])[1])]\n",
    "    stdB = np.array(stdB)\n",
    "    \n",
    "    return muM,muB,stdM,stdB\n",
    "\n",
    "comb = np.random.randint(10,size=16)\n",
    "muM,muB,stdM,stdB = entrenamiento(data,comb)\n",
    "print(rend(x_val))\n",
    "print(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con un vector de prueba se calcula el rendimiento, hagamos esto varias veces y elijamos el que tenga el mayor valor o el rendimiento "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rend = []; Comb = []\n",
    "for _ in range(10000):\n",
    "    comb = np.random.randint(10, size=16)\n",
    "    muM,muB,stdM,stdB = entrenamiento(data,comb)\n",
    "    Rend.append(rend(x_val))\n",
    "    Comb.append(comb)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Redimiento')"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Rend,\"r.\")\n",
    "plt.grid(True)\n",
    "plt.title(\"Valores del modelo\")\n",
    "plt.xlabel(\"Combinaciones\")\n",
    "plt.ylabel(\"Redimiento\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redimiento maximo = 0.9463414634146341\n",
      "Combinación utilizada [3 5 7 6 6 4 8 7 5 8 2 3 4 3 7 8] \n"
     ]
    }
   ],
   "source": [
    "print(\"Redimiento maximo = {}\".format(Rend[np.argmax(Rend)]))\n",
    "print(\"Combinación utilizada {} \".format(Comb[np.argmax(Rend)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
